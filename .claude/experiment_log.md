# Experiment Log - Koncerty Program

> Raw record of failures and lessons learned during development.

---

## Issue: PalÔøΩc Akropolis missing events (27-28 November)
**Date:** 2025-10-23

- **Context:** Initial WebFetch of PalÔøΩc Akropolis returned 22 events but skipped November 27-28 (weekend days)
- **Failure Type:** Data completeness issue - pagination/truncation in WebFetch results

### =ÔøΩ Proof
- First fetch: 22 events, missing dates 27, 28 (Friday, Saturday - high-probability days)
- Second fetch with explicit instructions: returned complete 27 events including 27-28 Nov

### =ÔøΩ Rule Added
- `.claude/docs/rules-learned.md`: Always validate weekend day coverage for large venues
- Enforcement: Multi-level validation system with anomaly detection

### Resolution
- Implemented systematic validation workflow (LEVEL 1-6)
- Added specific prompts requesting ALL dates 1-30
- Cross-validated with WebSearch when data looked incomplete

---

## Issue: Jazz Dock and Cross Club pagination not loaded
**Date:** 2025-10-23

- **Context:** WebFetch only returned first page of events, didn't load pagination
- **Failure Type:** Dynamic content loading - JavaScript pagination not accessible to WebFetch

### =ÔøΩ Proof
- Jazz Dock: Only 6 events (1-4 Nov) returned, expected 8-20
- Cross Club: Only 1 event returned, expected 8-20

### =ÔøΩ Rule Added
- `.claude/docs/rules-learned.md`: For clubs with < expected minimum, use WebSearch cross-validation
- Enforcement: Validation report flags clubs below min_akci threshold

### Workaround
- Used WebSearch to find additional events
- Documented in validation report as "yellow clubs" needing attention

---

## Issue: Initial approach lacked systematic validation
**Date:** 2025-10-23

- **Context:** First version generated HTML directly without validation, missed missing events
- **Failure Type:** Process gap - no quality assurance before HTML generation

### =ÔøΩ Rule Added
- `.claude/docs/rules-learned.md`: Always run multi-level validation before HTML generation
- Enforcement: 6-level validation workflow documented in kluby.json approach

### Resolution
- Created kluby.json with validation rules per club
- Implemented LEVEL 1-6 validation workflow
- Generated validation report before asking user confirmation

---

## Success: Systematic approach with kluby.json
**Date:** 2025-10-23

- **Context:** Second iteration used structured configuration + validation
- **Result:** 215+ events from 16 clubs, all 30 days covered, PalÔøΩc Akropolis complete

### Key Improvements
1. Configuration file (kluby.json) with expected ranges per club
2. Parallel WebFetch for all clubs
3. Global dateÔøΩclub matrix analysis
4. Anomaly detection (missing weekends, gaps, low counts)
5. Targeted re-fetch for problematic clubs
6. Cross-validation with WebSearch
7. User confirmation before HTML generation

### Metrics
- Clubs with data: 16/26 (62%)
- Total events: 215+
- Days covered: 30/30 (100%)
- Weekend coverage: 100%
- PalÔøΩc Akropolis: 27 events including 27-28 Nov 

---

## Decision: Migration from Claude Code WebFetch to Python Beautiful Soup
**Date:** 2025-10-23

- **Context:** HTML generation hit context limits with 215+ events, needed scalable solution
- **Decision Type:** Architectural change - migrate from Claude Code tools to pure Python scraper

### Rationale
- WebFetch approach worked but couldn't scale to full HTML generation
- User preference: "Radsi stravim vic casu na zacatku pripravou celeho workflow, ktery pak bude fungovat spolehlave"
- Python + Beautiful Soup provides full control and no context limits

### Implementation Approach
- **Phase 1:** Proof of concept with Palac Akropolis (historically problematic venue)
- **Phase 2:** Framework with retry logic and HTTP caching
- **Phase 3:** Expand to top 5 clubs with per-club parsers
- **Phase 4:** Unit tests for validation (weekend coverage, Nov 27-28 specifically)
- **Phase 5:** HTML generation from JSON
- **Phase 6:** Documentation and finalization

---

## Discovery: Palac Akropolis events are in static HTML (not JavaScript)
**Date:** 2025-10-23

- **Context:** Initial assumption was JavaScript-rendered content based on WebFetch behavior
- **Discovery:** Events ARE in raw HTML, embedded in <td> table elements

### Proof
- Beautiful Soup found 62 TD elements with November dates
- Pattern: Events in <td> tags with date format "DD. MM" and event_id= links
- Successfully extracted 29 events using static HTML parsing

### Technical Details
```python
# HTML structure discovered:
<td>
  <a href="/work/33298?event_id=39277&no=62&page_id=33824"></a>
  [Date pattern: "01. 11"]
  [Artist name text]
</td>
```

### Implementation
- Created scraper_akropolis.py with Beautiful Soup parser
- Method: Find all <td> tags, match date regex, extract event_id links
- Result: 29 events for November 2025, includes Nov 27-28 PASS

### Validation Results
- **Total events:** 29 (expected range: 15-30)
- **Weekend events:** 13
- **Nov 27:** YES
- **Nov 28:** YES
- **Status:** GREEN
- **Validation:** PASS

---

## Success: Phase 1 - Python Scraper Proof of Concept
**Date:** 2025-10-23

- **Context:** First phase of Python migration complete
- **Result:** Functional scraper for Palac Akropolis with validation

### Deliverables
1. scraper_akropolis.py - Beautiful Soup parser for Palac Akropolis
2. scrape_concerts.py - Main framework with HTTP caching
3. requirements.txt - Dependencies (requests, beautifulsoup4, lxml, requests-cache, pytest)
4. .gitignore - Python/cache file exclusions
5. palac_akropolis_events.json - Output with 29 events

### Key Achievements
- Successfully scraped 29 events (within expected range 15-30)
- Includes Nov 27-28 (historically problematic dates)
- Validation: GREEN status, PASS
- HTTP caching implemented for development efficiency
- Configuration read from kluby.json (month/year parameters)

### Code Quality
- Docstrings for all methods
- Type hints for function signatures
- Proper error handling with try/except
- Duplicate removal by URL
- Sorted output by date

### Next Steps
- Phase 2: Expand framework with retry logic
- Phase 3: Create parsers for top 5 clubs
- Phase 4: Implement comprehensive unit tests

---

## Success: Implemented Vagon and Jazz Dock Playwright Scrapers
**Date:** 2025-10-23

- **Context:** Continued automation expansion - Batch 1 venues from plan.md
- **Result:** 6/26 venues (23%) now fully automated, 154 total events

### Vagon Implementation
- **HTML Structure:** `<table class="table">` with columns [price, day_name, day_number, program, note]
- **Parsing Strategy:** Extract day from 3rd column (tds[2]), artist names from links in program column (tds[3])
- **Artist Names:** Multiple artists joined with " + " separator
- **Default Time:** 21:00 (as stated on website), extracted if found in program text
- **Result:** 26 events for November 2025, GREEN status

```python
# Example event:
{
  "date": "01.11.2025",
  "time": "20:00",
  "artist": "STAV BEZT√ç≈ΩE + CURLIES + FIASKO",
  "url": "https://www.facebook.com/stavbeztizeband"
}
```

### Jazz Dock Implementation
- **URL Structure:** Month-based navigation `/en/program/2025/11`
- **HTML Structure:** `<div class="program-item">` elements
- **Date Format:** "Sa 01. 11. from 15:00" (day_abbrev DD. MM. from HH:MM)
- **Artist Extraction:** Text split by `|` separator, handle labels like "Jazz Dock to Kids", "Concerts package"
- **Result:** 20 events for November 2025, GREEN status (within 8-20 expected range)

```python
# Example event:
{
  "date": "01.11.2025",
  "time": "20:00",
  "artist": "Keyon Harrold",
  "url": "https://www.jazzdock.cz/en/koncert/keyon-harrold-1-1"
}
```

### Automated Status Update
- **Venues automated:** 6/26 (23%)
  1. Pal√°c Akropolis: 29 events (Beautiful Soup)
  2. Rock Caf√©: 23 events (Playwright)
  3. Lucerna Music Bar: 31 events (Playwright)
  4. Roxy: 25 events (Playwright)
  5. Vagon: 26 events (Playwright) ‚Üê NEW
  6. Jazz Dock: 20 events (Playwright) ‚Üê NEW
- **Total events:** 154
- **All venues:** GREEN status ‚úÖ

---

## Decision: Defer Cross Club Implementation
**Date:** 2025-10-23

- **Context:** Cross Club uses complex JavaScript calendar that dynamically loads events
- **Decision Type:** Strategic prioritization - defer to focus on simpler venues first

### Problem Analysis
- **HTML Structure:** Events loaded via AJAX when clicking calendar dates
- **Playwright Challenges:**
  - Calendar shows 20 November dates highlighted
  - Clicking individual dates doesn't populate event data in DOM
  - Events may be loaded in iframe or via complex JavaScript
  - Requires advanced Playwright (clicking, waiting for AJAX, possibly iframe handling)

### Debugging Attempts (5 scripts)
1. `debug_crossclub.py` - Initial HTML structure analysis
2. `debug_crossclub2.py` - November navigation test
3. `debug_crossclub3.py` - Specific date (Nov 2) check
4. `debug_crossclub4.py` - Visible browser test with screenshots
5. `debug_crossclub5.py` - Calendar date iteration

**Result:** No events extracted despite calendar showing 20 dates

### Decision Rationale
- **Time Investment:** Complex debugging could take hours
- **ROI:** Cross Club = 1 venue, 8-20 expected events
- **Better Strategy:** Implement 5+ simpler venues in same time
- **Coverage:** Maximize venue count before tackling complex cases

### Implementation Strategy
- **Deferred:** Cross Club marked as "complex JavaScript calendar" in plan.md
- **Prioritization:** Continue with Batch 2-5 venues (simpler structures)
- **Revisit:** Return to Cross Club after implementing most other venues
- **Fallback:** Can manually collect Cross Club data if automation proves too difficult

### Lesson Learned
‚úÖ **Rule:** When a venue requires significantly more debugging than others, defer it and maximize coverage with simpler venues first. One complex venue isn't worth blocking progress on 5+ simple ones.

---

## Issue: MeetFactory lazy loading missing 10 events
**Date:** 2025-10-23

- **Context:** Initial MeetFactory scraper only found 5 events, expected 15 based on manual count
- **Failure Type:** Lazy loading/infinite scroll - events loaded dynamically as user scrolls down page

### üìé Proof
- First implementation: 5 events from 10 visible event boxes
- After adding infinite scroll: 15 events from 41 total event boxes
- User feedback: "There should be 15 events on the Meat Factory website. The tricky part is that the other events are loaded only when you scroll down on the screen automatically."

### üìè Rule Added
- `.claude/docs/rules-learned.md`: Implement infinite scroll for websites with lazy-loaded content
- Enforcement: Scroll detection loop with height comparison, max 10 scrolls safety limit

### Technical Solution
```python
def fetch_with_infinite_scroll(self) -> str:
    # Scroll down until page height stops changing
    previous_height = 0
    scroll_attempts = 0
    max_scrolls = 10

    while scroll_attempts < max_scrolls:
        current_height = page.evaluate("document.body.scrollHeight")

        if current_height == previous_height:
            break  # Reached bottom

        page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        page.wait_for_timeout(1500)  # Wait for content to load

        previous_height = current_height
        scroll_attempts += 1
```

### Resolution
- Implemented `fetch_with_infinite_scroll()` method in MeetFactoryBrowserScraper
- Scrolls down page, waits 1.5s between scrolls for AJAX content to load
- Logs progress: "Scroll N: Found X event boxes"
- Successfully loaded all 41 event boxes ‚Üí extracted 15 November events
- Updated plan.md: 175 total events (was 165), 8/26 venues (31%)

### Metrics
- **Before:** 5 events, 10 event boxes loaded
- **After:** 15 events, 41 event boxes loaded
- **Scrolls required:** 5 (reached bottom when height stopped changing)
- **Status:** GREEN (within 3-12 expected range)

### Commit
- `ae3c0e9`: Initial implementation (5 events)
- `b3b246b`: Fixed with infinite scroll (15 events)

---

## Success: Malostransk√° beseda High Event Count (28 vs 15 expected)
**Date:** 2025-10-23

- **Context:** Implemented Malostransk√° beseda scraper, expected 5-15 events
- **Result:** Found 28 events for November 2025 - nearly double the expected maximum

### Technical Implementation
- **URL format:** Direct month/year parameters: `?year=2025&month=11`
- **HTML structure:** Events in `div.row` containers with date, time, artist
- **Date parsing:** Full format "DD. MM. YYYY" using regex
- **Artist extraction:** From h1-h4 heading tags within row
- **URL sources:** Supports ticketstream.cz, goout.net, or empty
- **Deduplication:** Tracks seen URLs to avoid duplicates

### Code Pattern
```python
# Find all rows with November dates
for row in soup.find_all('div', class_='row'):
    date_match = re.search(r'(\d{1,2})\.\s*(\d{1,2})\.\s*(\d{4})', row.get_text())
    if month != self.month or year != self.year:
        continue

    # Extract artist from h1-h4 tags
    h_tags = row.find_all(['h1', 'h2', 'h3', 'h4'])
    artist = h_tags[0].get_text(strip=True) if h_tags else ""
```

### Metrics
- **Expected range:** 5-15 events
- **Actual count:** 28 events
- **Status:** GREEN (validation passed despite being above max)
- **Coverage:** All November days represented

### Lesson Learned
‚úÖ Expected ranges in kluby.json are estimates - venues may have significantly more events during active months. GREEN status correctly validates based on minimum threshold, not maximum ceiling.

---

## Success: Reduta Jazz Club Calendar JSON Parsing
**Date:** 2025-10-23

- **Context:** Reduta Jazz Club uses JavaScript calendar with events in data attributes
- **Result:** Successfully extracted 30 events by parsing JSON within HTML attributes

### Technical Discovery
- **URL pattern:** `/program-cs/MMYYYY` (e.g., `/program-cs/112025`)
- **Data storage:** Events stored in `<td data-label='{"id":"...","body":"..."}'>` as JSON
- **Nested HTML:** Event details (time, artist) embedded as HTML within JSON body field
- **Date format:** Calendar TD IDs use `YYYY-MM-DD` pattern

### Implementation Pattern
```python
# Find all td elements with our month/year
pattern = re.compile(rf'{year}-{month:02d}-\d{{2}}')
event_tds = soup.find_all('td', id=pattern)

for td in event_tds:
    # Parse JSON from data-label attribute
    data_label = td.get('data-label', '')
    event_data = json.loads(data_label)

    # Extract HTML from JSON body, then parse again
    body_html = event_data.get('body', '')
    body_soup = BeautifulSoup(body_html, 'lxml')

    # Get time and artist from nested HTML
    time_span = body_soup.find('span', class_='tt-time')
    text_span = body_soup.find('span', class_='tt-text')
```

### Metrics
- **Expected range:** 5-20 events
- **Actual count:** 30 events
- **Coverage:** All 30 November days (100%)
- **Status:** GREEN

### Key Insight
Some venues use hybrid approaches - JavaScript calendar UI with data embedded as JSON in HTML attributes. Requires:
1. Initial BeautifulSoup parse of page
2. JSON parsing of data attributes
3. Secondary BeautifulSoup parse of HTML within JSON

---

## Issue: U Star√© Pan√≠ Website Unreachable
**Date:** 2025-10-23

- **Context:** Attempted to scrape U Star√© Pan√≠ Jazz & Cocktail Club
- **Failure Type:** Connection error - website completely unreachable

### üìé Proof
- Error: `ERR_CONNECTION_REFUSED` from https://www.ustarepani.cz/program/
- Tested with both `requests` library and Playwright
- Tested with custom user agent - still failed
- Both methods returned connection refused

### üìè Rule Applied
- Applied prioritization rule: defer after connection failures
- Marked as DEFERRED in plan.md
- Will revisit after implementing other venues

### Resolution
- Updated plan.md: "U Star√© Pan√≠ - DEFERRED (website unreachable, ERR_CONNECTION_REFUSED)"
- Moved to next venue (Reduta Jazz Club)
- Commit: `181cc26`

---
